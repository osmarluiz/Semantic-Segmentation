{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "print(torch.__version__)\n",
    "from skimage.metrics import structural_similarity as ssim  # Import SSIM function\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import random\n",
    "import imageio\n",
    "from torchvision import transforms\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"D:/pytorch\")  # Adds the parent directory to the system path\n",
    "import segmentation_models_pytorch as smp\n",
    "from ipywidgets import widgets, VBox, HBox, IntText, ToggleButtons, Button, IntSlider, Label, Checkbox, Layout\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import shutil\n",
    "import gc\n",
    "import traceback\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# Use the widget backend for better interactivity in Jupyter\n",
    "%matplotlib widget\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "get_ipython().history_manager.enabled = False\n",
    "%config InlineBackend.close_figures = True\n",
    "\n",
    "!jupyter nbextension enable --py --sys-prefix ipympl\n",
    "!jupyter nbextension enable --py --sys-prefix widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"D:/SPARSE/\"\n",
    "train_imgs = glob(os.path.join(BASE_DIR, \"MULTICLASS/DENSE/image_train/*tiff\"))\n",
    "train_masks = glob(os.path.join(BASE_DIR, \"MULTICLASS/SPARSE/class_train/*png\"))\n",
    "\n",
    "val_imgs = glob(os.path.join(BASE_DIR, \"MULTICLASS/DENSE/image_val/*tiff\"))\n",
    "val_masks = glob(os.path.join(BASE_DIR, \"COMBINED_MASKS3/*png\"))\n",
    "#val_masks = glob(os.path.join(BASE_DIR, \"MULTICLASS/DENSE/class_val/*png\"))\n",
    "\n",
    "#val_imgs = glob(os.path.join(BASE_DIR, \"CAR/D_DATASET/image_val/*tiff\"))\n",
    "#val_masks = glob(os.path.join(BASE_DIR, \"CAR/D_DATASET/class_val/*png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pix_count(mask_images, ignore_index=None):\n",
    "    \"\"\"Counts pixels per class in a list of mask images.\"\"\"\n",
    "    pixel_counts = defaultdict(int)\n",
    "\n",
    "    for mask_path in mask_images:\n",
    "        mask = imageio.imread(mask_path).astype(int)\n",
    "        unique, counts = np.unique(mask, return_counts=True)\n",
    "        \n",
    "        # Dynamically apply ignore filtering\n",
    "        valid_pixels = {val: count for val, count in zip(unique, counts) if val != ignore_index}\n",
    "        for key, val in valid_pixels.items():\n",
    "            pixel_counts[key] += val\n",
    "\n",
    "    num_classes = max(pixel_counts.keys(), default=-1) + 1  # Handle empty cases\n",
    "    return dict(pixel_counts), num_classes\n",
    "\n",
    "pixel_counts, num_classes = pix_count(mask_images=train_masks, ignore_index=5)\n",
    "\n",
    "print(pixel_counts)\n",
    "print(\"Number of classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(data.Dataset):\n",
    "    def __init__(self, image_paths, target_paths, transform=None, transform_label=None, is_validation=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.target_paths = target_paths\n",
    "        self.transform = transform\n",
    "        self.transform_label = transform_label\n",
    "        self.is_validation = is_validation\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = imageio.imread(self.image_paths[index])\n",
    "        image = np.asarray(image, dtype='float32')\n",
    "        mask = imageio.imread(self.target_paths[index])\n",
    "        mask = np.asarray(mask, dtype='int64')\n",
    "        mask[mask > 5] = 5\n",
    "        \n",
    "        #if self.is_validation:\n",
    "        #    mask[mask == 2] = 0\n",
    "        \n",
    "        seed = np.random.randint(2147483647)\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        if self.transform_label:\n",
    "            mask = self.transform_label(mask)\n",
    "            mask = mask.squeeze(0)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = CustomDataset(train_imgs, train_masks, transform=transform, transform_label=transform)\n",
    "val_dataset = CustomDataset(val_imgs, val_masks, transform=transforms.ToTensor(), transform_label=None, is_validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "ENCODER = 'efficientnet-b7'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['class_0', 'class_1', 'class_2', 'class_3', 'class_4']  # Define the 5 classes\n",
    "ACTIVATION = 'softmax'  # Use softmax for multiclass segmentation\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'  # Use GPU if available, else CPU\n",
    "\n",
    "# Initialize the U-Net model with the specified encoder\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=len(CLASSES),\n",
    "    activation=ACTIVATION,\n",
    "    in_channels=3\n",
    ")\n",
    "\n",
    "# Get the preprocessing function for the chosen encoder\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# Choose the loss function. DiceLoss is commonly used for segmentation tasks.\n",
    "#d_loss = smp.utils.losses.DiceLoss(ignore_index=5)\n",
    "d_loss = smp.utils.losses.CrossEntropyLoss()\n",
    "loss = smp.utils.losses.DynamicWeightedConfidenceMulticlassDiceLoss(\n",
    "    eps=1.0,\n",
    "    beta=1.0,\n",
    "    amplification_factor=5.0,\n",
    "    confidence_threshold=0.8,\n",
    "    correctness_threshold=0.5,\n",
    "    activation=\"softmax\",\n",
    "    ignore_index=5  # Ensure ignore_index is handled properly\n",
    ")\n",
    "\n",
    "# Define the metric for evaluation. IoU (Intersection over Union) is a standard metric for segmentation.\n",
    "metrics = [smp.utils.metrics.mIoU()]\n",
    "\n",
    "# Initialize the optimizer. Adam is a popular choice for deep learning tasks.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=d_loss, \n",
    "    metrics=metrics, \n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10, shuffle=False, num_workers=0)\n",
    "valid_loader = torch.utils.data.DataLoader(val_dataset, batch_size=50, shuffle=False, num_workers=0)\n",
    "#test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=20, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop\n",
    "\n",
    "In this cell, we're executing the training loop for our segmentation model:\n",
    "\n",
    "- **Epochs**: We're training the model for a total of `100` epochs. In each epoch, the model is trained on the entire training dataset and then validated on the validation dataset.\n",
    "\n",
    "- **Monitoring Performance**: After each epoch, we print the Dice Loss for both training and validation to monitor the model's performance.\n",
    "\n",
    "- **Model Saving**: If the validation performance (measured by Dice Loss) improves compared to previous epochs, we save the model's state dictionary. This way, we ensure that we retain the model weights that give the best performance on the validation set. The model is saved as `T1_Car2.pth`.\n",
    "\n",
    "By the end of this loop, we aim to have a model that performs well on the validation dataset, indicating its potential to generalize well to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration dictionary for paths and settings\n",
    "BASE_DIR = \"D:/SPARSE/\"\n",
    "config = {\n",
    "    \"base_dir\": BASE_DIR,\n",
    "    \"data_folder\": os.path.join(BASE_DIR, \"SESSIONS/SESSIONS_MULTI/Session_v2\"),\n",
    "    \"epochs_per_iteration\": 300,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "\n",
    "train_imgs = glob(os.path.join(BASE_DIR, \"MULTICLASS/DENSE/image_train/*tiff\"))\n",
    "train_masks = glob(os.path.join(BASE_DIR, \"MULTICLASS/SPARSE/class_train/*png\"))\n",
    "\n",
    "val_imgs = glob(os.path.join(BASE_DIR, \"MULTICLASS/DENSE/image_val/*tiff\"))\n",
    "val_masks = glob(os.path.join(BASE_DIR, \"COMBINED_MASKS3/*png\"))\n",
    "#val_masks = glob(os.path.join(BASE_DIR, \"MULTICLASS/DENSE/class_val/*png\"))\n",
    "\n",
    "filename_map = {i: os.path.basename(mask) for i, mask in enumerate(train_masks)}\n",
    "\n",
    "# Set up paths within the main session data folder for iteration storage\n",
    "config[\"dataset_folder\"] = os.path.join(config[\"data_folder\"], \"datasets\")\n",
    "config[\"model_folder\"] = os.path.join(config[\"data_folder\"], \"models\")\n",
    "config[\"metrics_history_path\"] = os.path.join(config[\"data_folder\"], \"metrics_history.csv\")\n",
    "\n",
    "# Ensure directory structure is created if it doesn't exist\n",
    "os.makedirs(config[\"dataset_folder\"], exist_ok=True)\n",
    "os.makedirs(config[\"model_folder\"], exist_ok=True)\n",
    "\n",
    "# Widget controls setup\n",
    "transparency_slider = widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.05, description='Transparency:', continuous_update=True)\n",
    "label_selector = ToggleButtons(options=['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4'])\n",
    "\n",
    "forward_button = Button(description=\">\")\n",
    "backward_button = Button(description=\"<\")\n",
    "continue_training_button = Button(description=\"Continue Training\", layout=Layout(margin='20px 0px 0px 0px'))\n",
    "epoch_slider = IntSlider(value=config[\"epochs_per_iteration\"], min=1, max=100, description=\"Epochs:\")\n",
    "prediction_value_label = Label(value=\"Prediction: \")\n",
    "coordinates_label = Label(value=\"Coordinates: \")\n",
    "image_name_label = Label(value=\"Image: \")\n",
    "labeled_checkbox = Checkbox(description=\"Labeled\", value=False)\n",
    "\n",
    "# Initialize data structures\n",
    "predictions_cache = {}\n",
    "selected_points = defaultdict(list)\n",
    "changed_masks = set()\n",
    "images_labeled = set()\n",
    "current_image_index = 0\n",
    "current_iteration_points = defaultdict(list)\n",
    "min_dice_loss = float('inf')\n",
    "max_iou=0.0\n",
    "points_collected_total = 0\n",
    "dragging_point = None\n",
    "drag_start = None\n",
    "event_connections = []\n",
    "overlay = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetManager:\n",
    "    def __init__(self, config, train_imgs, train_masks, val_imgs, val_masks):\n",
    "        self.config = config\n",
    "        self.train_imgs = train_imgs\n",
    "        self.train_masks = train_masks\n",
    "        self.val_imgs = val_imgs\n",
    "        self.val_masks = val_masks\n",
    "        self.session_manager = SessionManager(config)\n",
    "\n",
    "        # Determine the dataset for initialization\n",
    "        latest_iteration = self.session_manager.get_current_iteration() - 1\n",
    "        if latest_iteration == 0:\n",
    "            self.modified_mask_dir = self.get_modified_mask_dir(0)\n",
    "            self._setup_initial_masks()\n",
    "        else:\n",
    "            self.modified_mask_dir = self.get_modified_mask_dir(latest_iteration)\n",
    "\n",
    "    def validate_masks(self, iteration):\n",
    "        \"\"\"Ensure all masks for the specified iteration exist.\"\"\"\n",
    "        iteration_dir = self.get_modified_mask_dir(iteration)\n",
    "        for img_id, mask_name in filename_map.items():\n",
    "            mask_path = os.path.join(iteration_dir, mask_name)\n",
    "            if not os.path.exists(mask_path):\n",
    "                raise FileNotFoundError(f\"Missing mask for img_id {img_id} in iteration {iteration}\")\n",
    "\n",
    "    def initialize_selected_points(self, selected_points):\n",
    "        \"\"\"Load labeled points from existing masks while ensuring deleted points are not reloaded.\"\"\"\n",
    "        latest_iteration_dir = self.modified_mask_dir\n",
    "        print(f\"[INFO] Initializing selected points from masks in {latest_iteration_dir}...\")\n",
    "\n",
    "        for img_id, mask_name in filename_map.items():\n",
    "            mask_path = os.path.join(latest_iteration_dir, mask_name)\n",
    "            if os.path.exists(mask_path):\n",
    "                mask = imageio.imread(mask_path)\n",
    "\n",
    "                # Extract labeled pixels (0-4), ignore class 5 (deleted)\n",
    "                labeled_positions = np.column_stack(np.where((mask >= 0) & (mask <= 4)))\n",
    "                labels = mask[labeled_positions[:, 0], labeled_positions[:, 1]]\n",
    "\n",
    "                # ✅ Store only valid points, skipping deleted pixels (class 5)\n",
    "                selected_points[img_id] = [\n",
    "                    (y, x, int(label))\n",
    "                    for (y, x), label in zip(labeled_positions, labels)\n",
    "                ]\n",
    "\n",
    "        print(f\"[INFO] Loaded selected points for {len(selected_points)} images.\")\n",
    "\n",
    "    def get_modified_mask_dir(self, iteration):\n",
    "        \"\"\"Return the directory for a specific iteration's masks.\"\"\"\n",
    "        return os.path.join(self.config[\"dataset_folder\"], f\"iteration_{iteration}\")\n",
    "    \n",
    "    def _setup_initial_masks(self):\n",
    "        \"\"\"Set up initial masks in iteration_0.\"\"\"\n",
    "        os.makedirs(self.modified_mask_dir, exist_ok=True)\n",
    "        for mask in self.train_masks:\n",
    "            shutil.copy(mask, os.path.join(self.modified_mask_dir, os.path.basename(mask)))\n",
    "\n",
    "    def save_all_masks(self, current_iteration):\n",
    "        \"\"\"\n",
    "        Save updated masks, ensuring that deletions are persisted.\n",
    "        Automatically retrieves selected_points and changed_masks from the DatasetManager.\n",
    "        \"\"\"\n",
    "        iteration_dir = self.get_modified_mask_dir(current_iteration)\n",
    "        previous_iteration_dir = self.get_modified_mask_dir(current_iteration - 1)\n",
    "\n",
    "        # Ensure the new iteration directory exists\n",
    "        os.makedirs(iteration_dir, exist_ok=True)\n",
    "\n",
    "        modified_count = 0  # Counter for modified masks\n",
    "\n",
    "        for img_id, mask_name in filename_map.items():\n",
    "            previous_mask_path = os.path.join(previous_iteration_dir, mask_name)\n",
    "            current_mask_path = os.path.join(iteration_dir, mask_name)\n",
    "\n",
    "            # ✅ **Copy previous mask to ensure it exists**\n",
    "            shutil.copy(previous_mask_path, current_mask_path)\n",
    "\n",
    "            # ✅ **Modify only if the mask was changed**\n",
    "            if img_id in changed_masks:\n",
    "                mask = imageio.imread(current_mask_path)\n",
    "\n",
    "                # ✅ **Remove deleted points by setting them to class 5 (unlabeled)**\n",
    "                existing_points = {(y, x) for y, x, _ in selected_points[img_id]}\n",
    "                for y in range(mask.shape[0]):\n",
    "                    for x in range(mask.shape[1]):\n",
    "                        if (y, x) not in existing_points and mask[y, x] != 5:\n",
    "                            mask[y, x] = 5  # Set deleted points to unlabeled (5)\n",
    "\n",
    "                # ✅ **Apply newly labeled points**\n",
    "                for y, x, label in selected_points[img_id]:\n",
    "                    mask[y, x] = label\n",
    "\n",
    "                # ✅ **Save the modified mask**\n",
    "                imageio.imsave(current_mask_path, mask)\n",
    "                modified_count += 1\n",
    "\n",
    "        print(f\"[INFO] Copied {len(filename_map)} masks from iteration {current_iteration - 1}.\")\n",
    "        print(f\"[INFO] Modified and saved {modified_count} masks for iteration {current_iteration}.\")\n",
    "\n",
    "        # ✅ **Clear changed masks tracking**\n",
    "        changed_masks.clear()\n",
    "\n",
    "    def count_class_pixels(self, iteration_dir):\n",
    "        \"\"\"Count the number of pixels for each class (0-4) in the masks of the given iteration.\"\"\"\n",
    "        class_counts = {i: 0 for i in range(5)}  # Initialize count for classes 0-4\n",
    "\n",
    "        for mask_file in os.listdir(iteration_dir):\n",
    "            mask_path = os.path.join(iteration_dir, mask_file)\n",
    "            mask = imageio.imread(mask_path)\n",
    "\n",
    "            # Count pixels for each class\n",
    "            for i in range(5):  # Ignore class 5\n",
    "                class_counts[i] += np.sum(mask == i)\n",
    "\n",
    "        return class_counts\n",
    "\n",
    "class SessionManager:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.current_iteration = self._get_latest_iteration() + 1  # Start from the next iteration\n",
    "        self.metrics_history = (\n",
    "            pd.read_csv(config[\"metrics_history_path\"])\n",
    "            if os.path.exists(config[\"metrics_history_path\"])\n",
    "            else pd.DataFrame(columns=[\n",
    "                'Iteration', 'Total_TP', 'Total_FP', 'Total_FN',  # Summed TP, FP, FN across classes\n",
    "                'mPrecision', 'mRecall', 'mF1-Score', 'mIoU'  # Mean precision, recall, F1-score, IoU\n",
    "            ] + [f'Class_{i}_{metric}' for i in range(5) for metric in ['TP', 'FP', 'FN', 'Precision', 'Recall', 'F1-Score', 'IoU']])\n",
    "        )\n",
    "\n",
    "    def _get_latest_iteration(self):\n",
    "        \"\"\"Determine the latest iteration based on available datasets.\"\"\"\n",
    "        dataset_folder = self.config[\"dataset_folder\"]\n",
    "        iteration_folders = [\n",
    "            int(folder.split(\"_\")[-1])\n",
    "            for folder in os.listdir(dataset_folder)\n",
    "            if folder.startswith(\"iteration_\") and folder.split(\"_\")[-1].isdigit()\n",
    "        ]\n",
    "        return max(iteration_folders, default=0)  # Default to 0 if no iterations exist\n",
    "\n",
    "    def increment_iteration(self):\n",
    "        \"\"\"Increment the iteration counter.\"\"\"\n",
    "        self.current_iteration += 1\n",
    "\n",
    "    def get_current_iteration(self):\n",
    "        \"\"\"Return the current iteration.\"\"\"\n",
    "        return self.current_iteration\n",
    "\n",
    "    def calculate_metrics_from_confusion_matrix(self, y_true, y_pred, num_classes=5):\n",
    "        \"\"\"Calculate evaluation metrics for multiclass segmentation.\"\"\"\n",
    "\n",
    "        # Compute confusion matrix for all classes (0-4)\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "\n",
    "        # Extract per-class TP, FP, FN, TN\n",
    "        tp = np.diag(cm)  # True Positives for each class\n",
    "        fn = cm.sum(axis=1) - tp  # False Negatives\n",
    "        fp = cm.sum(axis=0) - tp  # False Positives\n",
    "\n",
    "        # Compute precision, recall, and F1-score for each class\n",
    "        precision, recall, f1_score, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred, average=None, labels=list(range(num_classes))\n",
    "        )\n",
    "\n",
    "        # Compute per-class IoU\n",
    "        iou_per_class = tp / (tp + fp + fn + 1e-8)  # Avoid division by zero\n",
    "        mean_iou = np.mean(iou_per_class)  # Mean IoU across all classes\n",
    "\n",
    "        # Store metrics in a dictionary\n",
    "        metrics_dict = {\n",
    "            \"TP\": tp.tolist(),\n",
    "            \"FP\": fp.tolist(),\n",
    "            \"FN\": fn.tolist(),\n",
    "            \"Precision\": precision.tolist(),\n",
    "            \"Recall\": recall.tolist(),\n",
    "            \"F1-Score\": f1_score.tolist(),\n",
    "            \"IoU\": iou_per_class.tolist(),\n",
    "            \"Mean IoU\": mean_iou\n",
    "        }\n",
    "\n",
    "        return metrics_dict\n",
    "\n",
    "    def update_metrics_history(self, metrics_dict):\n",
    "        \"\"\"Update metrics history and save it to a CSV file.\"\"\"\n",
    "\n",
    "        # Compute totals across all classes\n",
    "        total_tp = sum(metrics_dict[\"TP\"])\n",
    "        total_fp = sum(metrics_dict[\"FP\"])\n",
    "        total_fn = sum(metrics_dict[\"FN\"])\n",
    "\n",
    "        # Compute mean metrics\n",
    "        mean_precision = np.mean(metrics_dict[\"Precision\"])\n",
    "        mean_recall = np.mean(metrics_dict[\"Recall\"])\n",
    "        mean_f1_score = np.mean(metrics_dict[\"F1-Score\"])\n",
    "        mean_iou = metrics_dict[\"Mean IoU\"]\n",
    "\n",
    "        # Prepare the metrics dictionary\n",
    "        metrics_data = {\n",
    "            \"Iteration\": self.current_iteration,\n",
    "            \"Total_TP\": total_tp, \"Total_FP\": total_fp, \"Total_FN\": total_fn,\n",
    "            \"mPrecision\": mean_precision, \"mRecall\": mean_recall, \"mF1-Score\": mean_f1_score, \"mIoU\": mean_iou\n",
    "        }\n",
    "\n",
    "        # Store per-class metrics\n",
    "        for i in range(5):\n",
    "            metrics_data[f'Class_{i}_TP'] = metrics_dict[\"TP\"][i]\n",
    "            metrics_data[f'Class_{i}_FP'] = metrics_dict[\"FP\"][i]\n",
    "            metrics_data[f'Class_{i}_FN'] = metrics_dict[\"FN\"][i]\n",
    "            metrics_data[f'Class_{i}_Precision'] = metrics_dict[\"Precision\"][i]\n",
    "            metrics_data[f'Class_{i}_Recall'] = metrics_dict[\"Recall\"][i]\n",
    "            metrics_data[f'Class_{i}_F1-Score'] = metrics_dict[\"F1-Score\"][i]\n",
    "            metrics_data[f'Class_{i}_IoU'] = metrics_dict[\"IoU\"][i]\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        new_metrics = pd.DataFrame([metrics_data])\n",
    "\n",
    "        # Update history\n",
    "        self.metrics_history = pd.concat([self.metrics_history, new_metrics], ignore_index=True)\n",
    "\n",
    "        # Save to disk\n",
    "        self.metrics_history.to_csv(self.config[\"metrics_history_path\"], index=False)\n",
    "        print(\"[INFO] Metrics history updated and saved.\")\n",
    "\n",
    "\n",
    "# ModelManager\n",
    "class ModelManager:\n",
    "    def __init__(self, config, model):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        \n",
    "    def save_model(self, iteration, is_best=False):\n",
    "        \"\"\"Save the model for a specific iteration.\"\"\"\n",
    "        if iteration == \"best_model\":\n",
    "            model_path = os.path.join(self.config[\"model_folder\"], \"best_model.pth\")\n",
    "        else:\n",
    "            model_path = os.path.join(self.config[\"model_folder\"], f\"iteration_{iteration}.pth\")\n",
    "\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "        if is_best:\n",
    "            print(f\"[INFO] Updated global best model at: {model_path}\")\n",
    "        else:\n",
    "            print(f\"[INFO] Model saved for iteration {iteration} at: {model_path}\")\n",
    "\n",
    "    def load_model(self, iteration):\n",
    "        \"\"\"Load the model for a specific iteration.\"\"\"\n",
    "        model_path = os.path.join(self.config[\"model_folder\"], f\"iteration_{iteration}.pth\")\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"[INFO] Loading model from: {model_path}\")\n",
    "            self.model.load_state_dict(torch.load(model_path))\n",
    "        else:\n",
    "            print(f\"[ERROR] Model not found for iteration {iteration}: {model_path}\")\n",
    "            raise FileNotFoundError(f\"Model not found: {model_path}\")\n",
    "\n",
    "    def cache_predictions(self, train_loader, device=\"cpu\"):\n",
    "        \"\"\"Cache predictions for active learning steps.\"\"\"\n",
    "        #print(f\"[DEBUG] Caching predictions using the current model...\")\n",
    "        self.model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "        predictions_cache = {}\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, _) in enumerate(train_loader):\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = self.model(inputs).cpu().numpy()\n",
    "                for i, output in enumerate(outputs):\n",
    "                    img_id = batch_idx * train_loader.batch_size + i\n",
    "                    predictions_cache[img_id] = {\n",
    "                        \"input\": np.transpose(inputs[i].cpu().numpy(), (1, 2, 0)),\n",
    "                        \"prediction\": output.squeeze()\n",
    "                    }\n",
    "        print(f\"[INFO] Cached predictions for {len(predictions_cache)} images.\")\n",
    "        return predictions_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_counts(img_id):\n",
    "    class_counts = {i: 0 for i in range(5)}  # Initialize counts for classes 0-4\n",
    "\n",
    "    for _, _, lbl in selected_points[img_id]:\n",
    "        if lbl in class_counts:\n",
    "            class_counts[lbl] += 1\n",
    "\n",
    "    for i in range(5):\n",
    "        print(f\"Class {i} Points: {class_counts[i]}\")\n",
    "\n",
    "def find_nearest_point(img_id, x, y, threshold=2):\n",
    "    for i, (py, px, _) in enumerate(selected_points[img_id]):\n",
    "        if abs(px - x) < threshold and abs(py - y) < threshold:\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "def delete_nearest_point(img_id, x, y):\n",
    "    \"\"\"\n",
    "    Deletes the nearest point in selected_points for a given image and coordinates.\n",
    "    Ensures the deletion is reflected in the saved masks.\n",
    "    \"\"\"\n",
    "    point_idx = find_nearest_point(img_id, x, y)\n",
    "    \n",
    "    if point_idx is not None:\n",
    "        # Extract deleted point\n",
    "        deleted_point = selected_points[img_id][point_idx]\n",
    "        y_coord, x_coord, label = deleted_point\n",
    "\n",
    "        # ✅ DEBUG: Before deletion\n",
    "        print(f\"[DEBUG] Before Deletion - Points in img {img_id}: {selected_points[img_id]}\")\n",
    "\n",
    "        # Remove from selected_points\n",
    "        selected_points[img_id].pop(point_idx)\n",
    "\n",
    "        # Also remove from `current_iteration_points`\n",
    "        current_iteration_points[img_id] = [\n",
    "            pt for pt in current_iteration_points[img_id] \n",
    "            if not (pt[0] == y_coord and pt[1] == x_coord)\n",
    "        ]\n",
    "\n",
    "        # ✅ Ensure the mask is marked as changed\n",
    "        changed_masks.add(img_id)\n",
    "\n",
    "        # ✅ DEBUG: After deletion\n",
    "        print(f\"[INFO] Deleted point at ({x_coord}, {y_coord}) for Class {label} in image {img_id}\")\n",
    "        print(f\"[DEBUG] After Deletion - Remaining Points: {selected_points[img_id]}\")\n",
    "\n",
    "        # ✅ Modify the mask directly\n",
    "        save_current_mask(delete_mode=True, img_id=img_id)\n",
    "    else:\n",
    "        print(f\"[WARNING] No point found near ({x}, {y}) in image {img_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_points(ax, img_id):\n",
    "    # Define colors for each class (adjust as needed)\n",
    "    class_colors = ['blue', 'green', 'yellow', 'orange', 'purple']\n",
    "\n",
    "    for y, x, label in selected_points[img_id]:\n",
    "        color = class_colors[label]  # Get color based on class index\n",
    "        ax.plot(x, y, 'o', color=color, markersize=4)  # Increase size for visibility\n",
    "\n",
    "# Event handlers for adding, dragging, and highlighting points\n",
    "def on_click(event):\n",
    "    global dragging_point\n",
    "    if event.inaxes:\n",
    "        x, y = int(event.xdata), int(event.ydata)\n",
    "        nearest_point_idx = find_nearest_point(current_image_index, x, y)\n",
    "\n",
    "        if nearest_point_idx is not None and event.button == 1:  # Left-click to start dragging\n",
    "            dragging_point = nearest_point_idx\n",
    "        elif event.button == 3:  # Right-click to delete the point\n",
    "            delete_nearest_point(current_image_index, x, y)\n",
    "            redraw_image_with_points(event.inaxes)\n",
    "        else:\n",
    "            # Extract the selected class index (e.g., 'Class 2' → 2)\n",
    "            label = int(label_selector.value.split()[-1])\n",
    "\n",
    "            # ✅ **Ensure changes are tracked**\n",
    "            selected_points[current_image_index].append((y, x, label))\n",
    "            current_iteration_points[current_image_index].append((y, x, label))\n",
    "            changed_masks.add(current_image_index)  # ✅ **Mark image as changed**\n",
    "            \n",
    "            # ✅ **Ensure UI and Data Update**\n",
    "            update_counts(current_image_index)\n",
    "            images_labeled.add(current_image_index)\n",
    "            labeled_checkbox.value = True\n",
    "\n",
    "            # ✅ **Save immediately**\n",
    "            save_current_mask()\n",
    "\n",
    "            # Redraw the image with the new point\n",
    "            redraw_image_with_points(event.inaxes)\n",
    "\n",
    "            \n",
    "def on_motion(event):\n",
    "    global dragging_point\n",
    "    if event.inaxes:\n",
    "        x, y = int(event.xdata), int(event.ydata)\n",
    "\n",
    "        # Get predicted class at (y, x)\n",
    "        predicted_class = predictions_cache[current_image_index][\"prediction\"].argmax(axis=0)[y, x]\n",
    "        prediction_value_label.value = f\"Prediction: Class {predicted_class}\"\n",
    "        coordinates_label.value = f\"Coordinates: ({x}, {y})\"\n",
    "\n",
    "        # Check if we're near an existing point\n",
    "        nearest_point_idx = find_nearest_point(current_image_index, x, y)\n",
    "\n",
    "        # Highlight nearest point if hovering\n",
    "        if nearest_point_idx is not None and dragging_point is None:\n",
    "            redraw_image_with_points(event.inaxes, highlight_idx=nearest_point_idx)\n",
    "        elif dragging_point is None:\n",
    "            redraw_image_with_points(event.inaxes)\n",
    "\n",
    "        # If dragging a point, update its position\n",
    "        if dragging_point is not None:\n",
    "            old_y, old_x, label = selected_points[current_image_index][dragging_point]\n",
    "            \n",
    "            # Update the dragged point's coordinates\n",
    "            selected_points[current_image_index][dragging_point] = (y, x, label)\n",
    "            \n",
    "            # Ensure the same point in `current_iteration_points` is updated\n",
    "            for i, (py, px, lbl) in enumerate(current_iteration_points[current_image_index]):\n",
    "                if py == old_y and px == old_x and lbl == label:\n",
    "                    current_iteration_points[current_image_index][i] = (y, x, label)\n",
    "                    break  # Stop once we find and update the point\n",
    "\n",
    "            # Mark the image as changed\n",
    "            changed_masks.add(current_image_index)\n",
    "            redraw_image_with_points(event.inaxes, highlight_idx=dragging_point)\n",
    "\n",
    "\n",
    "def on_release(event):\n",
    "    global dragging_point\n",
    "    dragging_point = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_train_loader():\n",
    "    global train_loader\n",
    "    current_iteration = session_manager.get_current_iteration()\n",
    "    previous_iteration_dir = dataset_manager.get_modified_mask_dir(current_iteration - 1)\n",
    "\n",
    "    updated_train_masks = [\n",
    "        os.path.join(previous_iteration_dir, filename_map[i])\n",
    "        for i in range(len(train_imgs))\n",
    "    ]\n",
    "\n",
    "    train_dataset = CustomDataset(train_imgs, updated_train_masks, transform=transform, transform_label=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10, shuffle=False, num_workers=0)\n",
    "\n",
    "def update_overlay_alpha(change):\n",
    "    \"\"\"Update overlay transparency.\"\"\"\n",
    "    global overlay\n",
    "\n",
    "    # Ensure overlay exists and is associated with the current image\n",
    "    if overlay is not None:\n",
    "        overlay.set_alpha(change['new'])  # Update transparency\n",
    "        #fig.canvas.draw_idle()\n",
    "        \n",
    "def save_current_mask(delete_mode=False, img_id=None):\n",
    "    \"\"\"\n",
    "    Saves the mask of the current image, ensuring all deletions and changes persist.\n",
    "    This is called before switching images to maintain consistency.\n",
    "    If `delete_mode` is True, it ensures deleted points are removed.\n",
    "    \"\"\"\n",
    "    if img_id is None:\n",
    "        img_id = current_image_index  # Default to current image if not specified\n",
    "\n",
    "    current_iteration = session_manager.get_current_iteration()\n",
    "    mask_path = os.path.join(dataset_manager.get_modified_mask_dir(current_iteration), filename_map[img_id])\n",
    "\n",
    "    if os.path.exists(mask_path):\n",
    "        mask = imageio.imread(mask_path)\n",
    "\n",
    "        # ✅ Get existing selected points\n",
    "        existing_points = {(y, x) for y, x, _ in selected_points[img_id]}\n",
    "        modified = False  \n",
    "\n",
    "        # ✅ Remove deleted points (Set them to unlabeled class 5)\n",
    "        for y in range(mask.shape[0]):\n",
    "            for x in range(mask.shape[1]):\n",
    "                if (y, x) not in existing_points and mask[y, x] != 5:\n",
    "                    mask[y, x] = 5  # Set deleted pixels to class 5\n",
    "                    modified = True  \n",
    "\n",
    "        # ✅ Save only if there were changes\n",
    "        if modified or img_id in changed_masks:\n",
    "            imageio.imsave(mask_path, mask)\n",
    "            print(f\"[INFO] Mask updated and saved for {mask_path}\")\n",
    "\n",
    "        # ✅ Ensure changes are tracked correctly\n",
    "        changed_masks.discard(img_id)\n",
    "\n",
    "    else:\n",
    "        print(f\"[WARNING] Mask file not found: {mask_path}. Skipping save.\")\n",
    "\n",
    "\n",
    "def on_forward_clicked(b):\n",
    "    \"\"\"\n",
    "    Saves the mask of the current image before navigating to the next.\n",
    "    Ensures that we can still move forward even if saving has issues.\n",
    "    \"\"\"\n",
    "    global current_image_index\n",
    "    save_current_mask()  # Save before switching\n",
    "\n",
    "    # ✅ Ensure navigation happens\n",
    "    next_index = (current_image_index + 1) % len(predictions_cache)\n",
    "\n",
    "    # ✅ Debug print\n",
    "    print(f\"[DEBUG] Moving forward: {current_image_index} → {next_index}\")\n",
    "\n",
    "    current_image_index = next_index\n",
    "    display_image(alpha=transparency_slider.value)\n",
    "\n",
    "def on_backward_clicked(b):\n",
    "    \"\"\"\n",
    "    Saves the mask of the current image before navigating to the previous.\n",
    "    Ensures that we can still move backward even if saving has issues.\n",
    "    \"\"\"\n",
    "    global current_image_index\n",
    "    save_current_mask()  # Save before switching\n",
    "\n",
    "    # ✅ Ensure navigation happens\n",
    "    prev_index = (current_image_index - 1) % len(predictions_cache)\n",
    "\n",
    "    # ✅ Debug print\n",
    "    print(f\"[DEBUG] Moving backward: {current_image_index} → {prev_index}\")\n",
    "\n",
    "    current_image_index = prev_index\n",
    "    display_image(alpha=transparency_slider.value)\n",
    "\n",
    "def on_continue_training_clicked(b):\n",
    "    clear_output()\n",
    "    current_iteration = session_manager.get_current_iteration()\n",
    "    print(f\"[INFO] Preparing iteration {current_iteration}...\")\n",
    "\n",
    "    # ✅ **Ensure all masks (including deletions) are saved before training**\n",
    "    dataset_manager.save_all_masks(current_iteration)\n",
    "\n",
    "    # ✅ **Increment iteration AFTER saving masks**\n",
    "    session_manager.increment_iteration()\n",
    "\n",
    "    # ✅ **Now it's safe to train**\n",
    "    run_training_loop()\n",
    "\n",
    "    # Reset UI elements\n",
    "    images_labeled.clear()\n",
    "    current_image_index = 0\n",
    "    current_iteration_points.clear()\n",
    "    display_image(alpha=transparency_slider.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(alpha=0.5):\n",
    "    global overlay, current_image_index, fig, ax  # Define fig and ax as global to manage their instance\n",
    "\n",
    "    # Clear previous output to prevent duplication\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # Create a new figure only if fig does not exist to prevent duplication\n",
    "    if 'fig' not in globals() or 'ax' not in globals():\n",
    "        fig, ax = plt.subplots(figsize=(7, 7))  # Create a new figure and axis\n",
    "\n",
    "    ax.clear()  # Clear the axis content if reusing the figure\n",
    "\n",
    "    # Check if the current index is valid\n",
    "    if current_image_index < 0 or current_image_index >= len(predictions_cache):\n",
    "        return\n",
    "\n",
    "    # Fetch current image and prediction data\n",
    "    img_data = predictions_cache[current_image_index]\n",
    "    inp_unit = img_data[\"input\"] / 255.0\n",
    "    ax.imshow(inp_unit, cmap='gray', aspect='auto')  # Display the grayscale input image without dimensions\n",
    "\n",
    "    # Convert multi-channel prediction (5, H, W) → (H, W) using argmax\n",
    "    prediction_map = img_data[\"prediction\"].argmax(axis=0)\n",
    "\n",
    "    # Add overlay for predictions with the initial transparency setting\n",
    "    overlay = ax.imshow(prediction_map, cmap='tab10', alpha=alpha, aspect='auto')\n",
    "\n",
    "    # Remove axis spines and labels for a clean visualization\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Adjust the layout before adding the title\n",
    "    fig.tight_layout(pad=1.0)\n",
    "\n",
    "    # Setup the title and other UI elements\n",
    "    changed_image_count = len(changed_masks)\n",
    "    points_collected_total = sum(len(points) for points in selected_points.values())\n",
    "    current_iteration_points_count = sum(len(points) for points in current_iteration_points.values())\n",
    "    fig.suptitle(f\"Images changed: {changed_image_count}, \"\n",
    "                 f\"Pts (current iteration): {current_iteration_points_count}, \"\n",
    "                 f\"Pts (total): {points_collected_total}\", fontsize=8)\n",
    "\n",
    "    image_name_label.value = f\"Image: {filename_map[current_image_index]}\"\n",
    "    labeled_checkbox.value = current_image_index in images_labeled\n",
    "\n",
    "    # Plot labeled points\n",
    "    plot_all_points(ax, current_image_index)\n",
    "\n",
    "    # Update alpha for the overlay directly\n",
    "    def update_overlay_alpha(change):\n",
    "        overlay.set_alpha(change['new'])\n",
    "        fig.canvas.draw_idle()  # Efficient redraw of the updated alpha only\n",
    "\n",
    "    # Add the observer again\n",
    "    transparency_slider.observe(update_overlay_alpha, names='value')\n",
    "\n",
    "    # Set up only one set of event connections per call\n",
    "    global event_connections\n",
    "    for cid in event_connections:\n",
    "        fig.canvas.mpl_disconnect(cid)\n",
    "    event_connections = [\n",
    "        fig.canvas.mpl_connect('button_press_event', on_click),\n",
    "        fig.canvas.mpl_connect('button_release_event', on_release),\n",
    "        fig.canvas.mpl_connect('motion_notify_event', on_motion)\n",
    "    ]\n",
    "\n",
    "    # Controls UI layout with improved order\n",
    "    controls_box = VBox([\n",
    "        # Layer 1: Class Selector (Horizontally aligned)\n",
    "        HBox([label_selector], layout=Layout(justify_content='flex-start')),\n",
    "\n",
    "        # Layer 2: Navigation buttons + Transparency slider\n",
    "        HBox([\n",
    "            backward_button,\n",
    "            forward_button,\n",
    "            transparency_slider\n",
    "        ], layout=Layout(justify_content='flex-start')),\n",
    "\n",
    "        # Layer 3: Image name & labeled checkbox\n",
    "        HBox([\n",
    "            image_name_label,\n",
    "            labeled_checkbox\n",
    "        ], layout=Layout(justify_content='flex-start')),\n",
    "\n",
    "        # Layer 4: Continue Training button\n",
    "        HBox([continue_training_button], layout=Layout(justify_content='flex-start'))\n",
    "    ])\n",
    "\n",
    "    # Explicitly display both the figure canvas and control elements\n",
    "    display(VBox([fig.canvas, controls_box]))\n",
    "\n",
    "    \n",
    "def redraw_image_with_points(ax, highlight_idx=None):\n",
    "    ax.clear()\n",
    "    img_data = predictions_cache[current_image_index]\n",
    "\n",
    "    # Display the input image\n",
    "    ax.imshow(img_data[\"input\"] / 255.0, cmap='gray', aspect='auto')\n",
    "\n",
    "    # Convert multi-channel prediction (C, H, W) → (H, W) using argmax\n",
    "    prediction_map = img_data[\"prediction\"].argmax(axis=0)\n",
    "\n",
    "    # Overlay the prediction mask with a categorical colormap\n",
    "    overlay = ax.imshow(prediction_map, cmap='tab10', alpha=transparency_slider.value, aspect='auto')\n",
    "\n",
    "    # Remove axis for a cleaner look\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Define class colors\n",
    "    class_colors = ['blue', 'green', 'yellow', 'red', 'pink']  # Adjust as needed for each class\n",
    "\n",
    "    # Plot labeled points\n",
    "    for i, (y, x, label) in enumerate(selected_points[current_image_index]):\n",
    "        color = class_colors[label]  # Assign color based on class index\n",
    "        size = 3 if i != highlight_idx else 5\n",
    "        ax.plot(x, y, 'o', color=color, markersize=size)\n",
    "\n",
    "    fig.canvas.draw_idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Training Loop\n",
    "def run_training_loop():\n",
    "    global min_dice_loss\n",
    "    current_iteration = session_manager.get_current_iteration()\n",
    "\n",
    "    print(f\"\\n--- Active Learning Iteration {current_iteration} ---\\n\")\n",
    "\n",
    "    # Load model from the previous iteration or initialize for the first iteration\n",
    "    if current_iteration > 1:\n",
    "        model_manager.load_model(current_iteration - 1)\n",
    "    else:\n",
    "        print(\"[INFO] Starting from scratch. Initializing model with default weights.\")\n",
    "\n",
    "    # Validate masks for the previous iteration\n",
    "    previous_iteration_dir = dataset_manager.get_modified_mask_dir(current_iteration - 1)\n",
    "    print(f\"[INFO] Validating masks for iteration {current_iteration - 1}...\")\n",
    "    dataset_manager.validate_masks(current_iteration - 1)\n",
    "    print(f\"[INFO] All masks validated for iteration {current_iteration - 1}.\")\n",
    "\n",
    "    # Count pixels for the current training dataset\n",
    "    class_counts = dataset_manager.count_class_pixels(previous_iteration_dir)\n",
    "\n",
    "    # Print class pixel counts dynamically\n",
    "    for i in range(5):\n",
    "        print(f\"[INFO] Class {i} pixels: {class_counts[i]}\")\n",
    "\n",
    "\n",
    "    # Reload train loader with masks from the previous iteration\n",
    "    reload_train_loader()\n",
    "\n",
    "    # Training loop\n",
    "    iteration_min_loss = float('inf')\n",
    "    for epoch in range(config[\"epochs_per_iteration\"]):\n",
    "        print(f\"[INFO] Epoch {epoch + 1}/{config['epochs_per_iteration']} (Iteration {current_iteration})\")\n",
    "        train_logs = train_epoch.run(train_loader)\n",
    "        valid_logs = valid_epoch.run(valid_loader)\n",
    "\n",
    "        # Save the best model for this iteration\n",
    "        if valid_logs['cross_entropy_loss'] < iteration_min_loss:\n",
    "            iteration_min_loss = valid_logs['cross_entropy_loss']\n",
    "            model_manager.save_model(current_iteration)\n",
    "\n",
    "        # Update the global best model if necessary\n",
    "        if valid_logs['cross_entropy_loss'] < min_dice_loss:\n",
    "            model_manager.save_model(\"best_model\", is_best=True)\n",
    "            min_dice_loss = valid_logs['cross_entropy_loss']\n",
    "\n",
    "    # Explicitly load the best model for this iteration\n",
    "    print(\"[INFO] Loading the best model for the current iteration...\")\n",
    "    model_manager.load_model(current_iteration)\n",
    "\n",
    "    # Cache predictions for active learning using the best model\n",
    "    global predictions_cache\n",
    "    predictions_cache = model_manager.cache_predictions(train_loader, config[\"device\"])\n",
    "    print(f\"[INFO] Cached predictions for {len(predictions_cache)} images.\")\n",
    "\n",
    "    # Update metrics history with class-wise pixel counts\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(config[\"device\"]), labels.to(config[\"device\"])\n",
    "            predictions = model(images).argmax(dim=1)  # Get class indices from softmax\n",
    "            y_true.extend(labels.cpu().numpy().flatten())\n",
    "            y_pred.extend(predictions.cpu().numpy().flatten())\n",
    "\n",
    "    # Compute multiclass metrics\n",
    "    metrics_dict = session_manager.calculate_metrics_from_confusion_matrix(y_true, y_pred, num_classes=5)\n",
    "\n",
    "    # Print per-class metrics\n",
    "    for i in range(5):\n",
    "        print(f\"[INFO] Class {i} - Precision: {metrics_dict['Precision'][i]:.2f}%, \"\n",
    "              f\"Recall: {metrics_dict['Recall'][i]:.2f}%, \"\n",
    "              f\"F1: {metrics_dict['F1-Score'][i]:.2f}%, IoU: {metrics_dict['IoU'][i]:.2f}%\")\n",
    "\n",
    "    print(f\"[INFO] Mean IoU: {metrics_dict['Mean IoU']:.2f}\")\n",
    "\n",
    "    # Store in history\n",
    "    session_manager.update_metrics_history(metrics_dict)\n",
    "    \n",
    "    print(\"\\nMetrics across iterations:\")\n",
    "    display(session_manager.metrics_history)\n",
    "    \n",
    "    # Display the first image of the new predictions\n",
    "    display_image(alpha=transparency_slider.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialization and Setup\n",
    "dataset_manager = DatasetManager(config, train_imgs, train_masks, val_imgs, val_masks)\n",
    "session_manager = SessionManager(config)\n",
    "model_manager = ModelManager(config, model)\n",
    "\n",
    "# Initialize selected points\n",
    "dataset_manager.initialize_selected_points(selected_points)\n",
    "\n",
    "# Observe transparency slider changes only once\n",
    "transparency_slider.observe(update_overlay_alpha, names='value')\n",
    "\n",
    "# Navigation handlers\n",
    "forward_button.on_click(on_forward_clicked)\n",
    "backward_button.on_click(on_backward_clicked)\n",
    "continue_training_button.on_click(on_continue_training_clicked)\n",
    "\n",
    "run_training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
