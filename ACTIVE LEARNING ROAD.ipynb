{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-matplotlib/extension...\n",
      "      - Validating: ok\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: ok\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "print(torch.__version__)\n",
    "from skimage.metrics import structural_similarity as ssim  # Import SSIM function\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import random\n",
    "import imageio\n",
    "from torchvision import transforms\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon\n",
    "import sys\n",
    "sys.path.append(\"D:/pytorch\")  # Adds the parent directory to the system path\n",
    "import segmentation_models_pytorch as smp\n",
    "from ipywidgets import widgets, VBox, HBox, IntText, ToggleButtons, Button, IntSlider, Label, Checkbox, Layout\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import shutil\n",
    "import gc\n",
    "import traceback\n",
    "\n",
    "# Use the widget backend for better interactivity in Jupyter\n",
    "%matplotlib widget\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "get_ipython().history_manager.enabled = False\n",
    "%config InlineBackend.close_figures = True\n",
    "\n",
    "!jupyter nbextension enable --py --sys-prefix ipympl\n",
    "!jupyter nbextension enable --py --sys-prefix widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"D:/SPARSE/\"\n",
    "train_imgs = glob(os.path.join(BASE_DIR, \"IMG/image_train/*tiff\"))\n",
    "train_masks = glob(os.path.join(BASE_DIR, \"ROAD/initial_dataset/*png\"))\n",
    "\n",
    "val_imgs = glob(os.path.join(BASE_DIR, \"ROAD/ROAD DATASET2/image_val/*tiff\"))\n",
    "val_masks = glob(os.path.join(BASE_DIR, \"ROAD/ROAD DATASET2/class_val/*png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1001, 1: 932}\n",
      "Number of classes: 2\n",
      "Overflow count: 0\n"
     ]
    }
   ],
   "source": [
    "def pix_count(mask_images, ignore_index=None):\n",
    "    pixel_counts = defaultdict(int)\n",
    "    overflow_count = 0\n",
    "\n",
    "    for mask_path in mask_images:\n",
    "        mask_image = imageio.imread(mask_path)\n",
    "        unique_values, unique_counts = np.unique(mask_image, return_counts=True)\n",
    "        \n",
    "        # Filter out the ignore_index if it is provided\n",
    "        if ignore_index is not None:\n",
    "            mask = unique_values != ignore_index\n",
    "            unique_values = unique_values[mask]\n",
    "            unique_counts = unique_counts[mask]\n",
    "        \n",
    "        for value, count in zip(unique_values, unique_counts):\n",
    "            pixel_counts[value] += count\n",
    "\n",
    "    # Determine number of classes based on the highest pixel value\n",
    "    num_classes = max(pixel_counts.keys()) + 1\n",
    "\n",
    "    # Check for and handle overflow (pixel values beyond num_classes)\n",
    "    for key in list(pixel_counts.keys()):\n",
    "        if key >= num_classes:\n",
    "            overflow_count += pixel_counts[key]\n",
    "            del pixel_counts[key]\n",
    "\n",
    "    return dict(pixel_counts), num_classes, overflow_count\n",
    "\n",
    "ignore_index_value = 2  # For example, to ignore white background\n",
    "pixel_counts, num_classes, overflow_count = pix_count(mask_images=train_masks, ignore_index=2)\n",
    "\n",
    "print(pixel_counts)\n",
    "print(\"Number of classes:\", num_classes)\n",
    "print(\"Overflow count:\", overflow_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(data.Dataset):\n",
    "    def __init__(self, image_paths, target_paths, transform=None, transform_label=None, is_validation=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.target_paths = target_paths\n",
    "        self.transform = transform\n",
    "        self.transform_label = transform_label\n",
    "        self.is_validation = is_validation\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = imageio.imread(self.image_paths[index])\n",
    "        image = np.asarray(image, dtype='float32')\n",
    "        mask = imageio.imread(self.target_paths[index])\n",
    "        mask = np.asarray(mask, dtype='int64')\n",
    "        mask[mask > 2] = 2\n",
    "        \n",
    "        if self.is_validation:\n",
    "            mask[mask == 2] = 0\n",
    "        \n",
    "        seed = np.random.randint(2147483647)\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        if self.transform_label:\n",
    "            mask = self.transform_label(mask)\n",
    "            mask = mask.squeeze(0)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "# augmentations used in the process\n",
    "transform = transforms.Compose([transforms.ToTensor()]) #,\n",
    "                                #transforms.RandomHorizontalFlip(),\n",
    "                                #transforms.RandomVerticalFlip()])\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(train_imgs, train_masks, transform=transform, transform_label=transform)\n",
    "val_dataset = CustomDataset(val_imgs, val_masks, transform=transforms.ToTensor(), transform_label=None, is_validation=True)\n",
    "#test_dataset = CustomDataset(test_imgs, test_masks, transform=transforms.ToTensor(), transform_label=None, is_validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "ENCODER = 'efficientnet-b7'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['car']  # For binary segmentation, only one class (car) is needed\n",
    "ACTIVATION = 'sigmoid' if len(CLASSES) == 1 else 'softmax'  # Use sigmoid for binary, softmax for multi-class\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'  # Use GPU if available, else CPU\n",
    "\n",
    "# Initialize the U-Net model with the specified encoder\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=len(CLASSES),\n",
    "    activation=ACTIVATION,\n",
    "    in_channels=3\n",
    ")\n",
    "\n",
    "# Get the preprocessing function for the chosen encoder\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Choose the loss function. DiceLoss is commonly used for segmentation tasks.\n",
    "d_loss = smp.utils.losses.DiceLoss(ignore_index=2)\n",
    "loss = smp.utils.losses.DynamicWeightedConfidenceDiceLoss(\n",
    "    eps=1.0,\n",
    "    beta=1.0,\n",
    "    amplification_factor=4.0,       # Amplify weights by a factor of 2 for confident incorrect predictions\n",
    "    confidence_threshold=0.8,       # Threshold for high confidence\n",
    "    correctness_threshold=0.5,      # Threshold for significant error\n",
    "    activation=\"sigmoid\",           # Use sigmoid activation for binary segmentation\n",
    "    ignore_index=2                  # Ignore unlabeled pixels if specified\n",
    ")\n",
    "\n",
    "# Define the metric for evaluation. IoU (Intersection over Union) is a standard metric for segmentation.\n",
    "metrics = [smp.utils.metrics.IoU()]\n",
    "\n",
    "# Initialize the optimizer. Adam is a popular choice for deep learning tasks.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=d_loss, \n",
    "    metrics=metrics, \n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10, shuffle=False, num_workers=0)\n",
    "valid_loader = torch.utils.data.DataLoader(val_dataset, batch_size=50, shuffle=False, num_workers=0)\n",
    "#test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=20, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop\n",
    "\n",
    "In this cell, we're executing the training loop for our segmentation model:\n",
    "\n",
    "- **Epochs**: We're training the model for a total of `100` epochs. In each epoch, the model is trained on the entire training dataset and then validated on the validation dataset.\n",
    "\n",
    "- **Monitoring Performance**: After each epoch, we print the Dice Loss for both training and validation to monitor the model's performance.\n",
    "\n",
    "- **Model Saving**: If the validation performance (measured by Dice Loss) improves compared to previous epochs, we save the model's state dictionary. This way, we ensure that we retain the model weights that give the best performance on the validation set. The model is saved as `T1_Car2.pth`.\n",
    "\n",
    "By the end of this loop, we aim to have a model that performs well on the validation dataset, indicating its potential to generalize well to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration dictionary for paths and settings\n",
    "BASE_DIR = \"D:/SPARSE/\"\n",
    "config = {\n",
    "    \"base_dir\": BASE_DIR,\n",
    "    \"data_folder\": os.path.join(BASE_DIR, \"SESSIONS/SESSIONS_ROAD/Session2\"),\n",
    "    \"epochs_per_iteration\": 50,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "\n",
    "\n",
    "# Original dataset paths\n",
    "train_imgs = glob(os.path.join(BASE_DIR, \"IMG/image_train/*tiff\"))\n",
    "train_masks = glob(os.path.join(BASE_DIR, \"ROAD/initial_dataset/*png\"))\n",
    "val_imgs = glob(os.path.join(BASE_DIR, \"ROAD/ROAD DATASET2/image_val/*tiff\"))\n",
    "val_masks = glob(os.path.join(BASE_DIR, \"ROAD/ROAD DATASET2/class_val/*png\"))\n",
    "filename_map = {i: os.path.basename(mask) for i, mask in enumerate(train_masks)}\n",
    "\n",
    "# Set up paths within the main session data folder for iteration storage\n",
    "config[\"dataset_folder\"] = os.path.join(config[\"data_folder\"], \"datasets\")\n",
    "config[\"model_folder\"] = os.path.join(config[\"data_folder\"], \"models\")\n",
    "config[\"metrics_history_path\"] = os.path.join(config[\"data_folder\"], \"metrics_history.csv\")\n",
    "\n",
    "# Ensure directory structure is created if it doesn't exist\n",
    "os.makedirs(config[\"dataset_folder\"], exist_ok=True)\n",
    "os.makedirs(config[\"model_folder\"], exist_ok=True)\n",
    "\n",
    "# Widget controls setup\n",
    "transparency_slider = widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.05, description='Transparency:', continuous_update=True)\n",
    "foreground_count = widgets.IntText(value=0, description=\"Foreground Points:\", disabled=True)\n",
    "background_count = widgets.IntText(value=0, description=\"Background Points:\", disabled=True)\n",
    "label_selector = ToggleButtons(options=['Foreground', 'Background'])\n",
    "forward_button = Button(description=\">\")\n",
    "backward_button = Button(description=\"<\")\n",
    "continue_training_button = Button(description=\"Continue Training\", layout=Layout(margin='20px 0px 0px 0px'))\n",
    "epoch_slider = IntSlider(value=config[\"epochs_per_iteration\"], min=1, max=100, description=\"Epochs:\")\n",
    "prediction_value_label = Label(value=\"Prediction: \")\n",
    "coordinates_label = Label(value=\"Coordinates: \")\n",
    "image_name_label = Label(value=\"Image: \")\n",
    "labeled_checkbox = Checkbox(description=\"Labeled\", value=False)\n",
    "\n",
    "# Initialize data structures\n",
    "predictions_cache = {}\n",
    "selected_points = defaultdict(list)\n",
    "changed_masks = set()\n",
    "images_labeled = set()\n",
    "current_image_index = 0\n",
    "current_iteration_points = defaultdict(list)\n",
    "min_dice_loss = float('inf')\n",
    "points_collected_total = 0\n",
    "dragging_point = None\n",
    "drag_start = None\n",
    "event_connections = []\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(7, 7))  # Default figure setup\n",
    "overlay = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DatasetManager\n",
    "class DatasetManager:\n",
    "    def __init__(self, config, train_imgs, train_masks, val_imgs, val_masks):\n",
    "        self.config = config\n",
    "        self.train_imgs = train_imgs\n",
    "        self.train_masks = train_masks\n",
    "        self.val_imgs = val_imgs\n",
    "        self.val_masks = val_masks\n",
    "        self.session_manager = SessionManager(config)\n",
    "\n",
    "        # Determine the dataset for initialization\n",
    "        latest_iteration = self.session_manager.get_current_iteration() - 1\n",
    "        if latest_iteration == 0:\n",
    "            self.modified_mask_dir = self.get_modified_mask_dir(0)\n",
    "            self._setup_initial_masks()\n",
    "        else:\n",
    "            self.modified_mask_dir = self.get_modified_mask_dir(latest_iteration)\n",
    "\n",
    "    def validate_masks(self, iteration):\n",
    "        \"\"\"Ensure all masks for the specified iteration exist.\"\"\"\n",
    "        iteration_dir = self.get_modified_mask_dir(iteration)\n",
    "        for img_id, mask_name in filename_map.items():\n",
    "            mask_path = os.path.join(iteration_dir, mask_name)\n",
    "            if not os.path.exists(mask_path):\n",
    "                raise FileNotFoundError(f\"Missing mask for img_id {img_id} in iteration {iteration}\")\n",
    "\n",
    "\n",
    "    def initialize_selected_points(self, selected_points):\n",
    "        \"\"\"Load labeled points from existing masks.\"\"\"\n",
    "        latest_iteration_dir = self.modified_mask_dir\n",
    "        print(f\"[INFO] Initializing selected points from masks in {latest_iteration_dir}...\")\n",
    "        for img_id, mask_name in filename_map.items():\n",
    "            mask_path = os.path.join(latest_iteration_dir, mask_name)\n",
    "            if os.path.exists(mask_path):\n",
    "                mask = imageio.imread(mask_path)\n",
    "                labeled_positions = np.argwhere((mask == 0) | (mask == 1))  # Assuming binary masks\n",
    "                labels = mask[labeled_positions[:, 0], labeled_positions[:, 1]]\n",
    "                selected_points[img_id].extend(\n",
    "                    [(y, x, label) for (y, x), label in zip(labeled_positions, labels)]\n",
    "                )\n",
    "        print(f\"[INFO] Loaded selected points for {len(selected_points)} images.\")\n",
    "\n",
    "    def get_modified_mask_dir(self, iteration):\n",
    "        \"\"\"Return the directory for a specific iteration's masks.\"\"\"\n",
    "        return os.path.join(self.config[\"dataset_folder\"], f\"iteration_{iteration}\")\n",
    "    \n",
    "    def _setup_initial_masks(self):\n",
    "        \"\"\"Set up initial masks in iteration_0.\"\"\"\n",
    "        os.makedirs(self.modified_mask_dir, exist_ok=True)\n",
    "        for mask in self.train_masks:\n",
    "            shutil.copy(mask, os.path.join(self.modified_mask_dir, os.path.basename(mask)))\n",
    "\n",
    "    def save_all_masks(self, selected_points, changed_masks, current_iteration):\n",
    "        \"\"\"\n",
    "        Save all masks (modified and unmodified) for the current iteration.\n",
    "        Unlabeled pixels are set to the value of 2.\n",
    "        \"\"\"\n",
    "        iteration_dir = self.get_modified_mask_dir(current_iteration)\n",
    "        previous_iteration_dir = self.get_modified_mask_dir(current_iteration - 1)\n",
    "        os.makedirs(iteration_dir, exist_ok=True)\n",
    "\n",
    "        modified_count = 0  # Counter for modified masks\n",
    "\n",
    "        for img_id, mask_name in filename_map.items():\n",
    "            previous_mask_path = os.path.join(previous_iteration_dir, mask_name)\n",
    "            current_mask_path = os.path.join(iteration_dir, mask_name)\n",
    "\n",
    "            # Copy unmodified masks directly\n",
    "            if img_id not in changed_masks:\n",
    "                shutil.copy(previous_mask_path, current_mask_path)\n",
    "                continue\n",
    "\n",
    "            # Overwrite with modified masks for images in `changed_masks`\n",
    "            mask = imageio.imread(previous_mask_path)\n",
    "            mask.fill(2)  # Reset the mask to `2` for unlabeled pixels\n",
    "\n",
    "            # Apply the labeled points from `selected_points`\n",
    "            for y, x, label in selected_points[img_id]:\n",
    "                mask[y, x] = label\n",
    "\n",
    "            # Save the updated mask\n",
    "            imageio.imsave(current_mask_path, mask)\n",
    "            modified_count += 1\n",
    "\n",
    "        print(f\"Total modified masks saved in iteration {current_iteration}: {modified_count}\")\n",
    "        print(f\"Total masks (including unmodified) saved in iteration {current_iteration}: {len(filename_map)}\")\n",
    "\n",
    "        # Clear `changed_masks` for the next iteration\n",
    "        changed_masks.clear()\n",
    "\n",
    "    def count_foreground_background_pixels(self, iteration_dir):\n",
    "        \"\"\"Count foreground and background pixels in the masks of the given iteration.\"\"\"\n",
    "        fg_count, bg_count = 0, 0\n",
    "        for mask_file in os.listdir(iteration_dir):\n",
    "            mask_path = os.path.join(iteration_dir, mask_file)\n",
    "            mask = imageio.imread(mask_path)\n",
    "            fg_count += np.sum(mask == 1)\n",
    "            bg_count += np.sum(mask == 0)\n",
    "        return fg_count, bg_count\n",
    "\n",
    "# SessionManager\n",
    "class SessionManager:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.current_iteration = self._get_latest_iteration() + 1  # Start from the next iteration\n",
    "        self.metrics_history = (\n",
    "            pd.read_csv(config[\"metrics_history_path\"])\n",
    "            if os.path.exists(config[\"metrics_history_path\"])\n",
    "            else pd.DataFrame(columns=[\n",
    "                'Iteration', 'TP', 'FP', 'FN', 'TN', \n",
    "                'Precision', 'Recall', 'F-Score', \n",
    "                'IoU', 'Foreground Pixels', 'Background Pixels'\n",
    "            ])\n",
    "        )\n",
    "\n",
    "    def _get_latest_iteration(self):\n",
    "        \"\"\"Determine the latest iteration based on available datasets.\"\"\"\n",
    "        dataset_folder = self.config[\"dataset_folder\"]\n",
    "        iteration_folders = [\n",
    "            int(folder.split(\"_\")[-1])\n",
    "            for folder in os.listdir(dataset_folder)\n",
    "            if folder.startswith(\"iteration_\") and folder.split(\"_\")[-1].isdigit()\n",
    "        ]\n",
    "        return max(iteration_folders, default=0)  # Default to 0 if no iterations exist\n",
    "\n",
    "    def increment_iteration(self):\n",
    "        \"\"\"Increment the iteration counter.\"\"\"\n",
    "        self.current_iteration += 1\n",
    "\n",
    "    def get_current_iteration(self):\n",
    "        \"\"\"Return the current iteration.\"\"\"\n",
    "        return self.current_iteration\n",
    "\n",
    "    def calculate_metrics_from_confusion_matrix(self, y_true, y_pred):\n",
    "        \"\"\"Calculate evaluation metrics from a confusion matrix.\"\"\"\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "        precision = tp / (tp + fp) * 100 if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) * 100 if (tp + fn) > 0 else 0\n",
    "        f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        iou = tp / (tp + fp + fn) * 100 if (tp + fp + fn) > 0 else 0\n",
    "        return int(tp), int(fp), int(fn), int(tn), round(precision, 2), round(recall, 2), round(f1_score, 2), round(iou, 2)\n",
    "\n",
    "    def update_metrics_history(self, tp, fp, fn, tn, precision, recall, f1_score, iou, fg_count, bg_count):\n",
    "        \"\"\"Update metrics history and save it to a CSV file.\"\"\"\n",
    "        new_metrics = pd.DataFrame([{\n",
    "            'Iteration': self.current_iteration,\n",
    "            'TP': tp,\n",
    "            'FP': fp,\n",
    "            'FN': fn,\n",
    "            'TN': tn,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F-Score': f1_score,\n",
    "            'IoU': iou,\n",
    "            'Foreground Pixels': fg_count,\n",
    "            'Background Pixels': bg_count\n",
    "        }])\n",
    "\n",
    "        # Use pd.concat for better performance\n",
    "        self.metrics_history = pd.concat([self.metrics_history, new_metrics], ignore_index=True)\n",
    "\n",
    "        # Save to disk\n",
    "        self.metrics_history.to_csv(self.config[\"metrics_history_path\"], index=False)\n",
    "        print(\"[INFO] Metrics history updated and saved.\")\n",
    "\n",
    "\n",
    "# ModelManager\n",
    "class ModelManager:\n",
    "    def __init__(self, config, model):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "\n",
    "        \n",
    "    def save_model(self, iteration, is_best=False):\n",
    "        \"\"\"Save the model for a specific iteration.\"\"\"\n",
    "        if iteration == \"best_model\":\n",
    "            model_path = os.path.join(self.config[\"model_folder\"], \"best_model.pth\")\n",
    "        else:\n",
    "            model_path = os.path.join(self.config[\"model_folder\"], f\"iteration_{iteration}.pth\")\n",
    "\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "        if is_best:\n",
    "            print(f\"[INFO] Updated global best model at: {model_path}\")\n",
    "        else:\n",
    "            print(f\"[INFO] Model saved for iteration {iteration} at: {model_path}\")\n",
    "\n",
    "    def load_model(self, iteration):\n",
    "        \"\"\"Load the model for a specific iteration.\"\"\"\n",
    "        model_path = os.path.join(self.config[\"model_folder\"], f\"iteration_{iteration}.pth\")\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"[INFO] Loading model from: {model_path}\")\n",
    "            self.model.load_state_dict(torch.load(model_path))\n",
    "        else:\n",
    "            print(f\"[ERROR] Model not found for iteration {iteration}: {model_path}\")\n",
    "            raise FileNotFoundError(f\"Model not found: {model_path}\")\n",
    "\n",
    "    def cache_predictions(self, train_loader, device=\"cpu\"):\n",
    "        \"\"\"Cache predictions for active learning steps.\"\"\"\n",
    "        #print(f\"[DEBUG] Caching predictions using the current model...\")\n",
    "        self.model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "        predictions_cache = {}\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, _) in enumerate(train_loader):\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = self.model(inputs).cpu().numpy()\n",
    "                for i, output in enumerate(outputs):\n",
    "                    img_id = batch_idx * train_loader.batch_size + i\n",
    "                    predictions_cache[img_id] = {\n",
    "                        \"input\": np.transpose(inputs[i].cpu().numpy(), (1, 2, 0)),\n",
    "                        \"prediction\": output.squeeze()\n",
    "                    }\n",
    "        print(f\"[INFO] Cached predictions for {len(predictions_cache)} images.\")\n",
    "        return predictions_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_counts(img_id):\n",
    "    fg_count = sum(1 for _, _, lbl in selected_points[img_id] if lbl == 1)\n",
    "    bg_count = sum(1 for _, _, lbl in selected_points[img_id] if lbl == 0)\n",
    "    foreground_count.value = fg_count\n",
    "    background_count.value = bg_count\n",
    "\n",
    "def find_nearest_point(img_id, x, y, threshold=2):\n",
    "    for i, (py, px, _) in enumerate(selected_points[img_id]):\n",
    "        if abs(px - x) < threshold and abs(py - y) < threshold:\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "def delete_nearest_point(img_id, x, y):\n",
    "    \"\"\"\n",
    "    Deletes the nearest point in the selected_points for a given image and coordinates.\n",
    "    Updates the associated data structures to ensure the deletion is reflected in masks.\n",
    "    \"\"\"\n",
    "    # Find the nearest point in selected_points\n",
    "    point_idx = find_nearest_point(img_id, x, y)\n",
    "    if point_idx is not None:\n",
    "        # Remove the point from selected_points\n",
    "        deleted_point = selected_points[img_id].pop(point_idx)\n",
    "        \n",
    "        # Update current_iteration_points by removing the corresponding point\n",
    "        current_iteration_points[img_id] = [\n",
    "            pt for pt in current_iteration_points[img_id] \n",
    "            if not (pt[0] == deleted_point[0] and pt[1] == deleted_point[1])]\n",
    "        \n",
    "        # Mark the image as changed\n",
    "        changed_masks.add(img_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_points(ax, img_id):\n",
    "    for y, x, label in selected_points[img_id]:\n",
    "        color = 'lime' if label == 1 else 'red'\n",
    "        ax.plot(x, y, 'o', color=color, markersize=3)\n",
    "\n",
    "# Event handlers for adding, dragging, and highlighting points\n",
    "def on_click(event):\n",
    "    global dragging_point\n",
    "    if event.inaxes:\n",
    "        x, y = int(event.xdata), int(event.ydata)\n",
    "        nearest_point_idx = find_nearest_point(current_image_index, x, y)\n",
    "\n",
    "        if nearest_point_idx is not None and event.button == 1:  # Left-click to start dragging\n",
    "            dragging_point = nearest_point_idx\n",
    "        elif event.button == 3:  # Right-click to delete the point\n",
    "            delete_nearest_point(current_image_index, x, y)\n",
    "            redraw_image_with_points(event.inaxes)\n",
    "        else:\n",
    "            label = 1 if label_selector.value == 'Foreground' else 0\n",
    "            selected_points[current_image_index].append((y, x, label))\n",
    "            current_iteration_points[current_image_index].append((y, x, label))\n",
    "            changed_masks.add(current_image_index)\n",
    "            update_counts(current_image_index)\n",
    "            images_labeled.add(current_image_index)\n",
    "            labeled_checkbox.value = True\n",
    "            redraw_image_with_points(event.inaxes)\n",
    "\n",
    "def on_motion(event):\n",
    "    global dragging_point\n",
    "    if event.inaxes:\n",
    "        x, y = int(event.xdata), int(event.ydata)\n",
    "        prediction_value_label.value = f\"Prediction: {predictions_cache[current_image_index]['prediction'][y, x]:.2f}\"\n",
    "        coordinates_label.value = f\"Coordinates: ({x}, {y})\"\n",
    "        \n",
    "        nearest_point_idx = find_nearest_point(current_image_index, x, y)\n",
    "        if nearest_point_idx is not None and dragging_point is None:\n",
    "            redraw_image_with_points(event.inaxes, highlight_idx=nearest_point_idx)\n",
    "        elif dragging_point is None:\n",
    "            redraw_image_with_points(event.inaxes)\n",
    "\n",
    "        if dragging_point is not None:\n",
    "            selected_points[current_image_index][dragging_point] = (y, x, selected_points[current_image_index][dragging_point][2])\n",
    "            redraw_image_with_points(event.inaxes, highlight_idx=dragging_point)\n",
    "\n",
    "def on_release(event):\n",
    "    global dragging_point\n",
    "    dragging_point = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_train_loader():\n",
    "    global train_loader\n",
    "    current_iteration = session_manager.get_current_iteration()\n",
    "    previous_iteration_dir = dataset_manager.get_modified_mask_dir(current_iteration - 1)\n",
    "\n",
    "    updated_train_masks = [\n",
    "        os.path.join(previous_iteration_dir, filename_map[i])\n",
    "        for i in range(len(train_imgs))\n",
    "]\n",
    "    train_dataset = CustomDataset(train_imgs, updated_train_masks, transform=transform, transform_label=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10, shuffle=False, num_workers=0)\n",
    "\n",
    "def update_overlay_alpha(change):\n",
    "    \"\"\"Update overlay transparency.\"\"\"\n",
    "    global overlay\n",
    "\n",
    "    # Ensure overlay exists and is associated with the current image\n",
    "    if overlay is not None:\n",
    "        overlay.set_alpha(change['new'])  # Update transparency\n",
    "        #fig.canvas.draw_idle()\n",
    "        \n",
    "# Navigation handlers\n",
    "def on_forward_clicked(b):\n",
    "    global current_image_index\n",
    "    forward_button.disabled = True\n",
    "    current_image_index = (current_image_index + 1) % len(predictions_cache)\n",
    "    display_image(alpha=transparency_slider.value)\n",
    "    forward_button.disabled = False\n",
    "\n",
    "def on_backward_clicked(b):\n",
    "    global current_image_index\n",
    "    backward_button.disabled = True\n",
    "    current_image_index = (current_image_index - 1) % len(predictions_cache)\n",
    "    display_image(alpha=transparency_slider.value)\n",
    "    backward_button.disabled = False\n",
    "        \n",
    "# On \"Continue Training\" Click\n",
    "def on_continue_training_clicked(b):\n",
    "    clear_output()\n",
    "    current_iteration = session_manager.get_current_iteration()\n",
    "    print(f\"[INFO] Saving masks for iteration {current_iteration}...\")\n",
    "    dataset_manager.save_all_masks(selected_points, changed_masks, current_iteration)\n",
    "\n",
    "    # Increment the iteration count *after* saving masks\n",
    "    session_manager.increment_iteration()\n",
    "\n",
    "    # Run training loop\n",
    "    run_training_loop()\n",
    "\n",
    "    # Reset UI elements\n",
    "    images_labeled.clear()\n",
    "    current_image_index = 0\n",
    "    current_iteration_points.clear()\n",
    "    display_image(alpha=transparency_slider.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(alpha=0.5):\n",
    "    global overlay, current_image_index, fig, ax  # Define fig and ax as global to manage their instance\n",
    "\n",
    "    # Clear previous output to prevent duplication\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # Create a new figure only if fig does not exist to prevent duplication\n",
    "    if 'fig' not in globals() or 'ax' not in globals():\n",
    "        fig, ax = plt.subplots(figsize=(7, 7))  # Create a new figure and axis\n",
    "\n",
    "    ax.clear()  # Clear the axis content if reusing the figure\n",
    "\n",
    "    # Check if the current index is valid\n",
    "    if current_image_index < 0 or current_image_index >= len(predictions_cache):\n",
    "        return\n",
    "\n",
    "    # Fetch current image and prediction data\n",
    "    img_data = predictions_cache[current_image_index]\n",
    "    inp_unit = img_data[\"input\"] / 255.0\n",
    "    ax.imshow(inp_unit, cmap='gray', aspect='auto')  # Display the grayscale input image without dimensions\n",
    "\n",
    "    # Add overlay for predictions with the initial transparency setting\n",
    "    overlay = ax.imshow(img_data[\"prediction\"], cmap='Reds', alpha=alpha, aspect='auto')\n",
    "\n",
    "    # Remove axis spines and labels for a clean visualization\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Adjust the layout before adding the title\n",
    "    fig.tight_layout(pad=1.0)\n",
    "\n",
    "    # Setup the title and other UI elements\n",
    "    changed_image_count = len(changed_masks)\n",
    "    points_collected_total = sum(len(points) for points in selected_points.values())\n",
    "    current_iteration_points_count = sum(len(points) for points in current_iteration_points.values())\n",
    "    fig.suptitle(f\"Images changed: {changed_image_count}, \"\n",
    "                 f\"Pts (current iteration): {current_iteration_points_count}, \"\n",
    "                 f\"Pts (total): {points_collected_total}\", fontsize=8)\n",
    "\n",
    "    image_name_label.value = f\"Image: {filename_map[current_image_index]}\"\n",
    "    labeled_checkbox.value = current_image_index in images_labeled\n",
    "\n",
    "    # Plot labeled points\n",
    "    plot_all_points(ax, current_image_index)\n",
    "\n",
    "    # Update alpha for the overlay directly\n",
    "    def update_overlay_alpha(change):\n",
    "        overlay.set_alpha(change['new'])\n",
    "        fig.canvas.draw_idle()  # Efficient redraw of the updated alpha only\n",
    "\n",
    "    # Add the observer again\n",
    "    transparency_slider.observe(update_overlay_alpha, names='value')\n",
    "\n",
    "    # Set up only one set of event connections per call\n",
    "    global event_connections\n",
    "    for cid in event_connections:\n",
    "        fig.canvas.mpl_disconnect(cid)\n",
    "    event_connections = [\n",
    "        fig.canvas.mpl_connect('button_press_event', on_click),\n",
    "        fig.canvas.mpl_connect('button_release_event', on_release),\n",
    "        fig.canvas.mpl_connect('motion_notify_event', on_motion)\n",
    "    ]\n",
    "\n",
    "    # Controls UI layout\n",
    "\n",
    "    controls_box = VBox([\n",
    "        HBox([\n",
    "            backward_button,    # < button\n",
    "            forward_button,     # > button\n",
    "            label_selector      # Foreground/Background\n",
    "        ]),\n",
    "        HBox([\n",
    "            transparency_slider,  # Transparency slider\n",
    "            image_name_label,     # Image number label\n",
    "            labeled_checkbox      # Labeled checkbox\n",
    "        ]),\n",
    "        HBox([\n",
    "            continue_training_button  # Continue Training button\n",
    "        ])\n",
    "    ])\n",
    "\n",
    "    # Explicitly display both the figure canvas and control elements\n",
    "    display(VBox([fig.canvas, controls_box]))\n",
    "\n",
    "def redraw_image_with_points(ax, highlight_idx=None):\n",
    "    ax.clear()  # Clear the axis content\n",
    "    img_data = predictions_cache[current_image_index]\n",
    "    ax.imshow(img_data[\"input\"] / 255.0, cmap='gray', aspect='auto')\n",
    "\n",
    "    # Update existing overlay\n",
    "    if overlay:\n",
    "        overlay.set_data(img_data[\"prediction\"])  # Update data\n",
    "        overlay.set_alpha(transparency_slider.value)\n",
    "    else:\n",
    "        overlay = ax.imshow(img_data[\"prediction\"], cmap='Reds', alpha=transparency_slider.value, aspect='auto')\n",
    "\n",
    "    ax.axis('off')  # Remove axis spines and labels\n",
    "\n",
    "    # Plot labeled points\n",
    "    for i, (y, x, label) in enumerate(selected_points[current_image_index]):\n",
    "        color = 'lime' if label == 1 else 'red'\n",
    "        size = 2 if i != highlight_idx else 4\n",
    "        ax.plot(x, y, 'o', color=color if i != highlight_idx else 'yellow', markersize=size)\n",
    "\n",
    "    fig.canvas.draw_idle()  # Efficient redraw\n",
    "\n",
    "    \n",
    "def redraw_image_with_points(ax, highlight_idx=None):\n",
    "    ax.clear()\n",
    "    img_data = predictions_cache[current_image_index]\n",
    "    ax.imshow(img_data[\"input\"] / 255.0, cmap='gray', aspect='auto')\n",
    "    overlay = ax.imshow(img_data[\"prediction\"], cmap='Reds', alpha=transparency_slider.value, aspect='auto')\n",
    "\n",
    "    # Remove axis for a cleaner look\n",
    "    ax.axis('off')\n",
    "\n",
    "    for i, (y, x, label) in enumerate(selected_points[current_image_index]):\n",
    "        color = 'lime' if label == 1 else 'red'\n",
    "        size = 2 if i != highlight_idx else 4\n",
    "        ax.plot(x, y, 'o', color=color if i != highlight_idx else 'yellow', markersize=size)\n",
    "\n",
    "    fig.canvas.draw_idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Training Loop\n",
    "def run_training_loop():\n",
    "    global min_dice_loss\n",
    "    current_iteration = session_manager.get_current_iteration()\n",
    "\n",
    "    print(f\"\\n--- Active Learning Iteration {current_iteration} ---\\n\")\n",
    "\n",
    "    # Load model from the previous iteration or initialize for the first iteration\n",
    "    if current_iteration > 1:\n",
    "        model_manager.load_model(current_iteration - 1)\n",
    "    else:\n",
    "        print(\"[INFO] Starting from scratch. Initializing model with default weights.\")\n",
    "\n",
    "    # Validate masks for the previous iteration\n",
    "    previous_iteration_dir = dataset_manager.get_modified_mask_dir(current_iteration - 1)\n",
    "    print(f\"[INFO] Validating masks for iteration {current_iteration - 1}...\")\n",
    "    dataset_manager.validate_masks(current_iteration - 1)\n",
    "    print(f\"[INFO] All masks validated for iteration {current_iteration - 1}.\")\n",
    "\n",
    "    # Count pixels for the current training dataset\n",
    "    fg_count, bg_count = dataset_manager.count_foreground_background_pixels(previous_iteration_dir)\n",
    "    print(f\"[INFO] Foreground pixels: {fg_count}, Background pixels: {bg_count}\")\n",
    "\n",
    "    # Reload train loader with masks from the previous iteration\n",
    "    reload_train_loader()\n",
    "\n",
    "    # Training loop\n",
    "    iteration_min_loss = float('inf')\n",
    "    for epoch in range(config[\"epochs_per_iteration\"]):\n",
    "        print(f\"[INFO] Epoch {epoch + 1}/{config['epochs_per_iteration']} (Iteration {current_iteration})\")\n",
    "        train_logs = train_epoch.run(train_loader)\n",
    "        valid_logs = valid_epoch.run(valid_loader)\n",
    "\n",
    "        # Save the best model for this iteration\n",
    "        if valid_logs['dice_loss'] < iteration_min_loss:\n",
    "            iteration_min_loss = valid_logs['dice_loss']\n",
    "            model_manager.save_model(current_iteration)\n",
    "\n",
    "        # Update the global best model if necessary\n",
    "        if valid_logs['dice_loss'] < min_dice_loss:\n",
    "            model_manager.save_model(\"best_model\", is_best=True)\n",
    "            min_dice_loss = valid_logs['dice_loss']\n",
    "\n",
    "    # Explicitly load the best model for this iteration\n",
    "    print(\"[INFO] Loading the best model for the current iteration...\")\n",
    "    model_manager.load_model(current_iteration)\n",
    "\n",
    "    # Cache predictions for active learning using the best model\n",
    "    global predictions_cache\n",
    "    predictions_cache = model_manager.cache_predictions(train_loader, config[\"device\"])\n",
    "    print(f\"[INFO] Cached predictions for {len(predictions_cache)} images.\")\n",
    "\n",
    "    # Update metrics history with foreground and background pixel counts\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(config[\"device\"]), labels.to(config[\"device\"])\n",
    "            predictions = model(images).round()\n",
    "            y_true.extend(labels.cpu().numpy().flatten())\n",
    "            y_pred.extend(predictions.cpu().numpy().flatten())\n",
    "    tp, fp, fn, tn, precision, recall, f1_score, iou = session_manager.calculate_metrics_from_confusion_matrix(y_true, y_pred)\n",
    "    session_manager.update_metrics_history(tp, fp, fn, tn, precision, recall, f1_score, iou, fg_count, bg_count)\n",
    "    print(f\"[INFO] Metrics updated for iteration {current_iteration}: \"\n",
    "          f\"Precision={precision:.2f}%, Recall={recall:.2f}%, F1={f1_score:.2f}%, IoU={iou:.2f}%\")   \n",
    "    \n",
    "    print(\"\\nMetrics across iterations:\")\n",
    "    display(session_manager.metrics_history)\n",
    "    \n",
    "    # Display the first image of the new predictions\n",
    "    display_image(alpha=transparency_slider.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27c9aac299a47e8ba4b5b898e8e3130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Baâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialization and Setup\n",
    "dataset_manager = DatasetManager(config, train_imgs, train_masks, val_imgs, val_masks)\n",
    "session_manager = SessionManager(config)\n",
    "model_manager = ModelManager(config, model)\n",
    "\n",
    "# Initialize selected points\n",
    "dataset_manager.initialize_selected_points(selected_points)\n",
    "\n",
    "# Observe transparency slider changes only once\n",
    "transparency_slider.observe(update_overlay_alpha, names='value')\n",
    "\n",
    "# Navigation handlers\n",
    "forward_button.on_click(on_forward_clicked)\n",
    "backward_button.on_click(on_backward_clicked)\n",
    "continue_training_button.on_click(on_continue_training_clicked)\n",
    "\n",
    "run_training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
